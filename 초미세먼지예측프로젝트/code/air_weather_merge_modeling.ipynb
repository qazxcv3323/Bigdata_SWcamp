{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f519928",
   "metadata": {
    "id": "8f519928"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "mpl.rc('font', family = 'Malgun Gothic') # 그래프 글꼴 설정 (window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e97d258",
   "metadata": {
    "id": "0e97d258"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/DMC CONET/Desktop/초미세먼지프로젝트/ty_data/result_output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febe6b2",
   "metadata": {
    "id": "6febe6b2"
   },
   "source": [
    "# AirKorea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c0c916",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "f7c0c916",
    "outputId": "6ad7f6aa-1252-4c39-b770-493b484ab81c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>오존</th>\n",
       "      <th>이산화질소</th>\n",
       "      <th>일산화탄소</th>\n",
       "      <th>아황산가스</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69516</th>\n",
       "      <td>2022-12-06 19:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69517</th>\n",
       "      <td>2022-12-06 20:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69518</th>\n",
       "      <td>2022-12-06 21:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69519</th>\n",
       "      <td>2022-12-06 22:00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69520</th>\n",
       "      <td>2022-12-06 23:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69521 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       날짜  PM10  PM2.5     오존  이산화질소  일산화탄소  아황산가스\n",
       "0     2015-01-01 01:00:00    44      7  0.022  0.011    0.6  0.006\n",
       "1     2015-01-01 02:00:00    57     10  0.022  0.010    0.6  0.006\n",
       "2     2015-01-01 03:00:00    76     10  0.021  0.010    0.6  0.006\n",
       "3     2015-01-01 04:00:00    86     11  0.022  0.009    0.6  0.006\n",
       "4     2015-01-01 05:00:00   106     12  0.021  0.009    0.5  0.006\n",
       "...                   ...   ...    ...    ...    ...    ...    ...\n",
       "69516 2022-12-06 19:00:00    17      8  0.017  0.032    0.4  0.003\n",
       "69517 2022-12-06 20:00:00    19     11  0.017  0.031    0.4  0.003\n",
       "69518 2022-12-06 21:00:00    17     10  0.018  0.029    0.4  0.003\n",
       "69519 2022-12-06 22:00:00    18      7  0.017  0.030    0.4  0.003\n",
       "69520 2022-12-06 23:00:00    19      7  0.008  0.041    0.5  0.003\n",
       "\n",
       "[69521 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air = pd.read_csv(path + 'air_2015_2022.csv') # row: 69521 , column : 7 \n",
    "air['날짜'] = pd.to_datetime(air['날짜'])\n",
    "air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5257e",
   "metadata": {
    "id": "0ac5257e"
   },
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e409df",
   "metadata": {
    "id": "43e409df"
   },
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc9123",
   "metadata": {
    "id": "14cc9123"
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv(path + 'weather_2015_2022.csv')\n",
    "weather['일시'] = pd.to_datetime(weather['일시'])\n",
    "\n",
    "# weather['year'] = weather['일시'].apply(lambda x : x.year)\n",
    "# weather['month'] = weather['일시'].apply(lambda x : x.month)\n",
    "# weather['day'] = weather['일시'].apply(lambda x : x.day)\n",
    "# weather['hour'] = weather['일시'].apply(lambda x: x.hour)\n",
    "# weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402c221",
   "metadata": {
    "id": "c402c221"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757dd93",
   "metadata": {
    "id": "b757dd93"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a8d9a77",
   "metadata": {
    "id": "7a8d9a77"
   },
   "source": [
    "# AirKorea + Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390ac30",
   "metadata": {
    "id": "9390ac30"
   },
   "outputs": [],
   "source": [
    "#결측치가 1건 발견되었음\n",
    "air_weather['일시'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d1546",
   "metadata": {
    "id": "ce2d1546"
   },
   "outputs": [],
   "source": [
    "# 확인해보니 2022 1월 1일 데이터가 없어 전값으로 채워도 무방하다고 판단.\n",
    "air_weather = air.merge(weather, left_on='날짜', right_on='일시', how='left')#.sum()\n",
    "cond = air_weather['일시'].isnull()\n",
    "air_weather.loc[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c7bd4",
   "metadata": {
    "id": "1a7c7bd4"
   },
   "outputs": [],
   "source": [
    "air_weather.iloc[61360:61362]\n",
    "\n",
    "# air_weather = air_weather.fillna(method='ffill') # 결측치를 이전값으로 채움\n",
    "\n",
    "air_weather = air_weather.fillna(0) # 결측치를 이전값으로 채움\n",
    "# air_weather['일시'].isnull().sum() # 결측치 없는것 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504e398",
   "metadata": {
    "id": "d504e398"
   },
   "outputs": [],
   "source": [
    "air_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504559f0",
   "metadata": {
    "id": "504559f0"
   },
   "outputs": [],
   "source": [
    "# air_weather.to_csv('C:/Users/DMC CONET/Desktop/초미세먼지프로젝트/ty_data/result_output/air_weather.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346015a",
   "metadata": {
    "id": "5346015a"
   },
   "outputs": [],
   "source": [
    "df_input = air_weather[['날짜', 'PM10', 'PM2.5', '오존', '이산화질소', '일산화탄소', '아황산가스', \n",
    "            '기온(°C)', '강수량(mm)', '풍속(m/s)', '풍향(16방위)', '습도(%)',\n",
    "            '증기압(hPa)', '이슬점온도(°C)', '현지기압(hPa)', '해면기압(hPa)', '지면온도(°C)',\n",
    "       '5cm 지중온도(°C)', '10cm 지중온도(°C)', '20cm 지중온도(°C)', '30cm 지중온도(°C)']]\n",
    "\n",
    "df_input['year'] = df_input['날짜'].apply(lambda x : x.year)\n",
    "df_input['month'] = df_input['날짜'].apply(lambda x : x.month)\n",
    "df_input['day'] = df_input['날짜'].apply(lambda x : x.day)\n",
    "df_input['hour'] = df_input['날짜'].apply(lambda x: x.hour)\n",
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0a23c",
   "metadata": {
    "id": "8ac0a23c"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "df_input['6h_PM2.5'] = df_input['PM2.5'].mean() # 평균값으로 초기화\n",
    "\n",
    "for i in range(6, len(df_input['6h_PM2.5'])):  # 6시간후라 range 6 부터 시작\n",
    "    df_input['6h_PM2.5'].iloc[i-6] = df_input['PM2.5'][i]\n",
    "\n",
    "print(f'코드 동작시간은 ? : {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc8c69",
   "metadata": {
    "id": "f1dc8c69"
   },
   "outputs": [],
   "source": [
    "df_input['6h_PM2.5'] = df_input['6h_PM2.5'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fcf26",
   "metadata": {
    "id": "765fcf26"
   },
   "outputs": [],
   "source": [
    "X = df_input[['PM10', 'PM2.5', '오존', '이산화질소', '일산화탄소', '아황산가스', \n",
    "            '기온(°C)', '강수량(mm)', '풍속(m/s)', '풍향(16방위)', '습도(%)',\n",
    "            ]] # '증기압(hPa)', '이슬점온도(°C)', '현지기압(hPa)', '해면기압(hPa)', '지면온도(°C)',\n",
    "       '5cm 지중온도(°C)', '10cm 지중온도(°C)', '20cm 지중온도(°C)', '30cm 지중온도(°C)',\n",
    "             'year', 'month', 'day', 'hour'\n",
    "y = df_input['6h_PM2.5']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3affc9",
   "metadata": {
    "id": "df3affc9"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b3393",
   "metadata": {
    "id": "555b3393"
   },
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789f4ea",
   "metadata": {
    "id": "5789f4ea"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns # for correlation heatmap\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776eaeec",
   "metadata": {
    "id": "776eaeec"
   },
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(n_estimators=100)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e67a6",
   "metadata": {
    "id": "1a3e67a6"
   },
   "outputs": [],
   "source": [
    "xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67241641",
   "metadata": {
    "id": "67241641"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(X.columns.tolist(), xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffc3a5",
   "metadata": {
    "id": "32ffc3a5"
   },
   "source": [
    "나은 플롯을 얻으려 중요도 값을 기준으로 기능을 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b459e45",
   "metadata": {
    "id": "8b459e45"
   },
   "outputs": [],
   "source": [
    "X_fn = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d0150",
   "metadata": {
    "id": "f86d0150"
   },
   "outputs": [],
   "source": [
    "sorted_idx = xgb.feature_importances_.argsort()\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.barh(X_fn, xgb.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4602ddf",
   "metadata": {
    "id": "f4602ddf"
   },
   "source": [
    "**Permutation Based Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cbe90",
   "metadata": {
    "id": "fc1cbe90"
   },
   "outputs": [],
   "source": [
    "perm_importance = permutation_importance(xgb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80840a4b",
   "metadata": {
    "id": "80840a4b"
   },
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(X.columns.tolist(), perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cd52d",
   "metadata": {
    "id": "af5cd52d"
   },
   "outputs": [],
   "source": [
    "def correlation_heatmap(train):\n",
    "    correlations = train.corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    sns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f', cmap=\"YlGnBu\",\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70}\n",
    "                )\n",
    "    plt.show();\n",
    "    \n",
    "correlation_heatmap(X_train[X.columns.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d83b76",
   "metadata": {
    "id": "52d83b76"
   },
   "source": [
    "**Feature Importance Computed with SHAP Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c627e",
   "metadata": {
    "id": "fb8c627e"
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95941be",
   "metadata": {
    "id": "d95941be"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ca0fc",
   "metadata": {
    "id": "9b1ca0fc"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9795e09",
   "metadata": {
    "id": "c9795e09"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"hour\", shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde0eb2",
   "metadata": {
    "id": "adde0eb2"
   },
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f604259",
   "metadata": {
    "id": "7f604259"
   },
   "outputs": [],
   "source": [
    "# 2. 지도학습에 필요한 라이브러리를 호출\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose        import make_column_transformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.pipeline      import pipeline\n",
    "from imblearn.pipeline      import make_pipeline\n",
    "from sklearn.impute         import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing  import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV    # 교차검증\n",
    "from sklearn.metrics   import classification_report     # 평가\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor # Bagging Model \n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e447cc2",
   "metadata": {
    "id": "8e447cc2"
   },
   "outputs": [],
   "source": [
    "# 4. 파이프라인을 구성한다.\n",
    "numeric_pipe = make_pipeline(KNNImputer(), MinMaxScaler())\n",
    "# category_pipe = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "numeric_list = X.describe().columns.tolist()\n",
    "# category_list = X.describe(include='object').columns.tolist()\n",
    "\n",
    "preprocessing_pipe = make_column_transformer((numeric_pipe, numeric_list)\n",
    "#                                             , (category_pipe, category_list)\n",
    "                                            )\n",
    "\n",
    "model_pipe = make_pipeline(preprocessing_pipe, RandomForestRegressor())\n",
    "# 5. 교차검증 및 하이퍼 파라미터 튜닝\n",
    "hyperparameter_list = {'randomforestregressor__max_depth':range(5,11)\n",
    "                        , 'randomforestregressor__min_samples_leaf':range(5,11)\n",
    "                        , 'randomforestregressor__min_samples_split':range(5,11)}\n",
    "grid_model = GridSearchCV(model_pipe, param_grid={}\n",
    "                            , cv=5, n_jobs=-1, scoring='f1')# , error_score='raise'\n",
    "grid_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. 평가\n",
    "best_model = grid_model.best_estimator_\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f'y_train_pred : {y_train_pred}\\n')\n",
    "print(f'y_test_pred : {y_test_pred}\\n')\n",
    "# 평가\n",
    "print(f'r2_score_train : {r2_score(y_train, y_train_pred)}\\n')\n",
    "print(f'r2_score_test : {r2_score(y_test, y_test_pred)}\\n')\n",
    "\n",
    "# encoder_list = best_model.named_steps['columntransformer'].transformers_[1][1].named_steps['onehotencoder'].get_feature_names().tolist()\n",
    "# df_importance = pd.DataFrame()\n",
    "# df_importance['Feature'] = pd.Series(numeric_list + encoder_list)\n",
    "\n",
    "\n",
    "# df_importance['Importance']= best_model['randomforestregressor'].feature_importances_\n",
    "# df_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print('explained_variance_score: {}'.format(explained_variance_score(y_train, y_train_pred)))\n",
    "print('mean_squared_errors: {}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('r2_score: {}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "print('explained_variance_score: {}'.format(explained_variance_score(y_test, y_test_pred)))\n",
    "print('mean_squared_errors: {}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('r2_score: {}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eecc5c",
   "metadata": {
    "id": "19eecc5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "# 4. 파이프라인을 구성한다.\n",
    "numeric_pipe = make_pipeline(KNNImputer(), MinMaxScaler())\n",
    "# category_pipe = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "numeric_list = X.describe().columns.tolist()\n",
    "# category_list = X.describe(include='object').columns.tolist()\n",
    "\n",
    "preprocessing_pipe = make_column_transformer((numeric_pipe, numeric_list)\n",
    "#                                             , (category_pipe, category_list)\n",
    "                                            )\n",
    "\n",
    "model_pipe = make_pipeline(preprocessing_pipe, RandomForestRegressor())\n",
    "\n",
    "# 5. 교차검증 및 하이퍼 파라미터 튜닝\n",
    "hyperparameter_list = {'randomforestregressor__max_depth':range(5,11)\n",
    "                        , 'randomforestregressor__min_samples_leaf':range(5,11)\n",
    "                        , 'randomforestregressor__min_samples_split':range(5,11)}\n",
    "grid_model = GridSearchCV(model_pipe, param_grid=hyperparameter_list\n",
    "                            , cv=5, n_jobs=-1, scoring='f1')# , error_score='raise'\n",
    "grid_model.fit(X_train, y_train)\n",
    "\n",
    "# 6. 평가\n",
    "best_model = grid_model.best_estimator_\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f'y_train_pred : {y_train_pred}\\n')\n",
    "print(f'y_test_pred : {y_test_pred}\\n')\n",
    "# 평가\n",
    "print(f'r2_score_train : {r2_score(y_train, y_train_pred)}\\n')\n",
    "print(f'r2_score_test : {r2_score(y_test, y_test_pred)}\\n')\n",
    "\n",
    "# encoder_list = best_model.named_steps['columntransformer'].transformers_[1][1].named_steps['onehotencoder'].get_feature_names().tolist()\n",
    "# df_importance = pd.DataFrame()\n",
    "# df_importance['Feature'] = pd.Series(numeric_list + encoder_list)\n",
    "\n",
    "\n",
    "# df_importance['Importance']= best_model['randomforestregressor'].feature_importances_\n",
    "# df_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print('explained_variance_score: {}'.format(explained_variance_score(y_train, y_train_pred)))\n",
    "print('mean_squared_errors: {}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('r2_score: {}'.format(r2_score(y_train, y_train_pred)))\n",
    "\n",
    "print('explained_variance_score: {}'.format(explained_variance_score(y_test, y_test_pred)))\n",
    "print('mean_squared_errors: {}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('r2_score: {}'.format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f9a497",
   "metadata": {
    "id": "56f9a497"
   },
   "source": [
    "# stats model - 통계적 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6236d",
   "metadata": {
    "id": "c5c6236d"
   },
   "outputs": [],
   "source": [
    "# 실습용 데이터 패키지 \n",
    "from sklearn.datasets import load_boston \n",
    "\n",
    "# 데이터 전처리 패키지 \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd # 기계학습 모델 구축 및 평가 패키지 \n",
    "\n",
    "import scipy as sp \n",
    "import scipy.stats as stats \n",
    "import statsmodels.api as sm \n",
    "\n",
    "from statsmodels.formula.api import ols \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error \n",
    "\n",
    "\n",
    "\n",
    "# CHOTE A 3X \n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as pit \n",
    "import matplotlib.font_manager as fm \n",
    "# 한글 폰트 설정 \n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327ea43",
   "metadata": {
    "id": "7327ea43"
   },
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train, axis=1)\n",
    "model_trained = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b6766",
   "metadata": {
    "id": "b99b6766"
   },
   "outputs": [],
   "source": [
    "model_trained.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b146ee",
   "metadata": {
    "id": "f0b146ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_residuals = model_trained.resid\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False # 음수 폰트깨짐 방지\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "sm.ProbPlot(model_residuals).qqplot(line='s', color='#1f77b4', ax=ax)\n",
    "ax.title.set_text('QQplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f2f23",
   "metadata": {
    "id": "0a2f2f23"
   },
   "source": [
    "**확률오차의 등분산성 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69affd9",
   "metadata": {
    "id": "b69affd9"
   },
   "outputs": [],
   "source": [
    "model_fitted_y = model_trained.fittedvalues\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "sns.residplot(model_fitted_y, y_train, data=X, lowess=True, scatter_kws={'alpha':0.5},\n",
    "            line_kws={'color':'red'}, ax=ax)\n",
    "ax.title.set_text('Residuals vs Fitted')\n",
    "ax.set(xlabel='Fitted values', ylabel='Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071de01",
   "metadata": {
    "id": "a071de01"
   },
   "source": [
    "**통계적 접근해보기**\n",
    "\n",
    "- R_squard(결정계수) : 모형의 성능\n",
    "- coef(회귀계수) : X가 한단위 증가할 때 Y의 변화량\n",
    "- P >[t](p_value): 0.05(유의수준) 이하일 때 변수가 유의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08492baa",
   "metadata": {
    "id": "08492baa"
   },
   "outputs": [],
   "source": [
    "print(model_trained.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0e025",
   "metadata": {
    "id": "55b0e025"
   },
   "source": [
    "**p_value 0.05이상 : '10cm 지중온도(°C)', '5cm 지중온도(°C)', '일산화탄소', '이슬점온도(°C)'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce552079",
   "metadata": {
    "id": "ce552079"
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, X_train.drop(columns=['10cm 지중온도(°C)', '5cm 지중온도(°C)', '일산화탄소', '이슬점온도(°C)']))\n",
    "model_trained = model.fit()\n",
    "print(model_trained.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bf401",
   "metadata": {
    "id": "a45bf401"
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train, X_train.drop(columns=['10cm 지중온도(°C)', '5cm 지중온도(°C)', '일산화탄소', '이슬점온도(°C)', '현지기압(hPa)', '증기압(hPa)', '해면기압(hPa)', '지면온도(°C)']))\n",
    "model_trained = model.fit()\n",
    "print(model_trained.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a12f26",
   "metadata": {
    "id": "f7a12f26"
   },
   "outputs": [],
   "source": [
    "# 성능에는 크게 변화가없지만, 개선이 직접적으로 되지않더라고 통계량값들의 해석을 할때 훨씬더 유의미한 해석이 이루어 질 수 있다.\n",
    "# 스스로 개선 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8710420",
   "metadata": {
    "id": "f8710420"
   },
   "outputs": [],
   "source": [
    "y_train_pred = model_trained.fittedvalues\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.title('실제값 vs 모델 출력 값')\n",
    "plt.scatter(y_train, y_train_pred)\n",
    "plt.plot([-5, 100], [-5, 100], ls='--', c='red')\n",
    "plt.xlabel('실제값', size=16)\n",
    "plt.ylabel('모델 출력 값', size=16)\n",
    "plt.xlim(-5, 100)\n",
    "plt.ylim(-5, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bf238",
   "metadata": {
    "id": "433bf238"
   },
   "outputs": [],
   "source": [
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344713d8",
   "metadata": {
    "id": "344713d8"
   },
   "outputs": [],
   "source": [
    "y_test_pred=model_trained.predict(X_test.drop(columns=['10cm 지중온도(°C)', '5cm 지중온도(°C)', '일산화탄소', '이슬점온도(°C)']))\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af228c98",
   "metadata": {
    "id": "af228c98"
   },
   "outputs": [],
   "source": [
    "# Mean Squrd Error\n",
    "print(f'MSE : {mean_squared_error(y_train, y_train_pred)}')\n",
    "\n",
    "# Root Mean Squrd Error\n",
    "print(f'RMSE : {np.sqrt(mean_squared_error(y_train, y_train_pred))}')\n",
    "\n",
    "# Root Mean Absolute Error\n",
    "print(f'MAE : {mean_absolute_error(y_train, y_train_pred)}')\n",
    "\n",
    "def Mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs(y_true - y_pred) / y_true) * 100\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "print(f'MAPE : {Mean_absolute_percentage_error(y_train, y_train_pred)}') # Mean_absolute_percentage_error\n",
    "\n",
    "print(f'R2 : {r2_score(y_train, y_train_pred)}') # r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47a341",
   "metadata": {
    "id": "bb47a341"
   },
   "outputs": [],
   "source": [
    "# Mean Squrd Error\n",
    "print(f'MSE : {mean_squared_error(y_test, y_test_pred)}')\n",
    "\n",
    "# Root Mean Squrd Error\n",
    "print(f'RMSE : {np.sqrt(mean_squared_error(y_test, y_test_pred))}')\n",
    "\n",
    "# Root Mean Absolute Error\n",
    "print(f'MAE : {mean_absolute_error(y_test, y_test_pred)}')\n",
    "\n",
    "def Mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs(y_true - y_pred) / y_true) * 100\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "print(f'MAPE : {Mean_absolute_percentage_error(y_test, y_test_pred)}') # Mean_absolute_percentage_error\n",
    "\n",
    "print(f'R2 : {r2_score(y_test, y_test_pred)}') # r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de474f9",
   "metadata": {
    "id": "2de474f9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "743c020d",
   "metadata": {
    "id": "743c020d"
   },
   "source": [
    "# 시계열처리 - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01b10e",
   "metadata": {
    "id": "ff01b10e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(777) #하이퍼파라미터 튜닝을 위해 실행시 마다 변수가 같은 초기값 가지게 하기\n",
    "import numpy as np\n",
    "#matplotlib 패키지 한글 깨짐 처리 시작\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "if platform.system() == 'Darwin': #맥\n",
    "        plt.rc('font', family='AppleGothic') \n",
    "elif platform.system() == 'Windows': #윈도우\n",
    "        plt.rc('font', family='Malgun Gothic') \n",
    "elif platform.system() == 'Linux': #리눅스 (구글 콜랩)\n",
    "        #!wget \"https://www.wfonts.com/download/data/2016/06/13/malgun-gothic/malgun.ttf\"\n",
    "        #!mv malgun.ttf /usr/share/fonts/truetype/\n",
    "        #import matplotlib.font_manager as fm \n",
    "        #fm._rebuild() \n",
    "        plt.rc('font', family='Malgun Gothic') \n",
    "plt.rcParams['axes.unicode_minus'] = False #한글 폰트 사용시 마이너스 폰트 깨짐 해결\n",
    "#matplotlib 패키지 한글 깨짐 처리 끝\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c0ab5",
   "metadata": {
    "id": "3b7c0ab5"
   },
   "outputs": [],
   "source": [
    "def load_time_series_data(data, sequence_length):\n",
    "    #print(data.shape) #(1225, 1)\n",
    "    #print(sequence_length) #3\n",
    "    window_length = sequence_length + 1\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for i in range(0, len(data) - window_length + 1): #0 1 2 3 4 5 6 7 8 9 | 10\n",
    "        window = data[i:i + window_length, :]\n",
    "        x_data.append(window[:-1, :])\n",
    "        y_data.append(window[-1, [-1]])\n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "    #print(x_data.shape) #(1222, 3, 1)\n",
    "    #print(y_data.shape) #(1222, 1)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd4988",
   "metadata": {
    "id": "2afd4988"
   },
   "outputs": [],
   "source": [
    "df_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc4d1c",
   "metadata": {
    "id": "66bc4d1c"
   },
   "outputs": [],
   "source": [
    "data = df_input[['6h_PM2.5']].to_numpy()\n",
    "print(data.shape) #((720, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7ebb3",
   "metadata": {
    "id": "5df7ebb3"
   },
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler()\n",
    "data = transformer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6af0f4",
   "metadata": {
    "id": "4c6af0f4"
   },
   "outputs": [],
   "source": [
    "df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bb261",
   "metadata": {
    "id": "b44bb261"
   },
   "outputs": [],
   "source": [
    "sequence_length = 26\n",
    "x_data, y_data = load_time_series_data(data, sequence_length)\n",
    "x_data = x_data.reshape(len(x_data), -1)\n",
    "print(x_data.shape) #(69518, 3)\n",
    "print(y_data.shape) #(69518, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04125e",
   "metadata": {
    "id": "0e04125e"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, shuffle=False) #시각화를 위해 shuffle=False 옵션 사용\n",
    "print(x_train.shape)  # (48662, 3)\n",
    "print(y_train.shape) # (48662, 1)\n",
    "print(x_test.shape)# (20856, 3)\n",
    "print(y_test.shape) # (20856, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1051104",
   "metadata": {
    "id": "b1051104"
   },
   "outputs": [],
   "source": [
    "##########모델 생성\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(sequence_length,))\n",
    "net = tf.keras.layers.Dense(units=32, activation='relu')(input)\n",
    "net = tf.keras.layers.Dense(units=32, activation='relu')(net)\n",
    "net = tf.keras.layers.Dense(units=1)(net)\n",
    "model = tf.keras.models.Model(input, net)\n",
    "\n",
    "##########모델 학습\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=40, validation_data=(x_test, y_test)) \n",
    "\n",
    "##########모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b060d2c",
   "metadata": {
    "id": "3b060d2c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.plot(df_input['6h_PM2.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186cfda",
   "metadata": {
    "id": "4186cfda"
   },
   "outputs": [],
   "source": [
    "##########모델 예측                           \n",
    "\n",
    "def plot(data, y_predict_train, y_predict_test):\n",
    "#     plt.figure(figsize=(20, 20))\n",
    "    plt.plot(transformer.inverse_transform(data)[:, [-1]].flatten(), label='실제 종가')\n",
    "\n",
    "    y_predict_train = transformer.inverse_transform(y_predict_train)\n",
    "    y_predict_train_plot = np.empty_like(data[:, [0]])\n",
    "    y_predict_train_plot[:, :] = np.nan\n",
    "    y_predict_train_plot[sequence_length:len(y_predict_train) + sequence_length, :] = y_predict_train\n",
    "    plt.plot(y_predict_train_plot.flatten(), label='학습 데이터 예측 종가')\n",
    "\n",
    "    y_predict_test = transformer.inverse_transform(y_predict_test)\n",
    "    y_predict_test_plot = np.empty_like(data[:, [0]])\n",
    "    y_predict_test_plot[:, :] = np.nan\n",
    "    y_predict_test_plot[len(y_predict_train) + sequence_length:, :] = y_predict_test\n",
    "    plt.plot(y_predict_test_plot.flatten(), label='테스트 데이터 예측 종가')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "y_predict_train = model.predict(x_train)\n",
    "y_predict_test = model.predict(x_test)\n",
    "plot(data, y_predict_train, y_predict_test)\n",
    "\n",
    "# # 검증\n",
    "# x_test = np.array([\n",
    "#         [44, 49, 50]\n",
    "# ])\n",
    "# x_test = x_test.reshape(-1, 1)\n",
    "# x_test = transformer.transform(x_test)\n",
    "# x_test = x_test.reshape(1, sequence_length)\n",
    "\n",
    "# y_predict = model.predict(x_test)\n",
    "\n",
    "# y_predict = transformer.inverse_transform(y_predict)\n",
    "# print(y_predict[0][0]) #51.707638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26c3fa",
   "metadata": {
    "id": "1d26c3fa"
   },
   "outputs": [],
   "source": [
    "# rnn, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9009d",
   "metadata": {
    "id": "dec9009d"
   },
   "outputs": [],
   "source": [
    "df_RNN = df_input[['PM10', 'PM2.5', '오존', '이산화질소', '일산화탄소', '아황산가스', '기온(°C)',\n",
    "       '강수량(mm)', '풍속(m/s)', '풍향(16방위)', '습도(%)', '증기압(hPa)', '이슬점온도(°C)',\n",
    "       '현지기압(hPa)', '해면기압(hPa)', '지면온도(°C)', '5cm 지중온도(°C)', '10cm 지중온도(°C)',\n",
    "       '20cm 지중온도(°C)', '30cm 지중온도(°C)', 'year', 'month', 'day', 'hour',\n",
    "       '6h_PM2.5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23339ed2",
   "metadata": {
    "id": "23339ed2"
   },
   "outputs": [],
   "source": [
    "sequence_x = 7*24\n",
    "sequence_y = 24\n",
    "m = len(df_RNN) - (sequence_x + sequence_y) +1\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b34f0",
   "metadata": {
    "id": "ae4b34f0"
   },
   "outputs": [],
   "source": [
    "df_RNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28088abe",
   "metadata": {
    "id": "28088abe"
   },
   "outputs": [],
   "source": [
    "feature_k = df_RNN.shape[-1]\n",
    "(m, sequence_x, feature_k),(m, sequence_y, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ef839",
   "metadata": {
    "id": "842ef839"
   },
   "outputs": [],
   "source": [
    "data_x = np.zeros((m, sequence_x, feature_k), np.float32)\n",
    "data_y = np.zeros((m, sequence_y, 1), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67257521",
   "metadata": {
    "id": "67257521"
   },
   "outputs": [],
   "source": [
    "np.array(df_RNN).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc818cd",
   "metadata": {
    "id": "9cc818cd"
   },
   "outputs": [],
   "source": [
    "df_arr = np.array(df_RNN)\n",
    "df_arr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0d7f1",
   "metadata": {
    "id": "ecf0d7f1"
   },
   "outputs": [],
   "source": [
    "df_RNN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11079f2",
   "metadata": {
    "id": "f11079f2"
   },
   "outputs": [],
   "source": [
    "df_arr_i = df_arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3e662",
   "metadata": {
    "id": "3fa3e662"
   },
   "outputs": [],
   "source": [
    "fg = pd.DataFrame(df_arr_i[:5], columns= df_arr_i)\n",
    "fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68295745",
   "metadata": {
    "id": "68295745"
   },
   "outputs": [],
   "source": [
    "for i in range(m):\n",
    "    data_x[i] = df_arr[i : i+sequence_x]\n",
    "    data_y[i] = df_arr[i + sequence_x : i + sequence_x + sequence_y + -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a5892",
   "metadata": {
    "id": "600a5892"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560c22e",
   "metadata": {
    "id": "f560c22e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d6ad9",
   "metadata": {
    "id": "d17d6ad9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2326f53",
   "metadata": {
    "id": "e2326f53"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da4ea5",
   "metadata": {
    "id": "47da4ea5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375a5fd",
   "metadata": {
    "id": "9375a5fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66194f90",
   "metadata": {
    "id": "66194f90"
   },
   "source": [
    "**참고 : https://github.com/rickiepark/deep-learning-with-python-notebooks/blob/master/6.4-sequence-processing-with-convnets.ipynb**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f86f8",
   "metadata": {
    "id": "a32f86f8"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "\n",
    "max_features = 10000  # 특성으로 사용할 단어의 수\n",
    "max_len = 500  # 사용할 텍스트의 길이(가장 빈번한 max_features 개의 단어만 사용합니다)\n",
    "\n",
    "print('데이터 로드...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), '훈련 시퀀스')\n",
    "print(len(x_test), '테스트 시퀀스')\n",
    "\n",
    "print('시퀀스 패딩 (samples x time)')\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train 크기:', x_train.shape)\n",
    "print('x_test 크기:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727b27c",
   "metadata": {
    "id": "4727b27c"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['loss'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d677f8a",
   "metadata": {
    "id": "7d677f8a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
